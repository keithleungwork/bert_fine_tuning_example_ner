{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tunning the model \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
    "\n",
    "> Originated from https://github.com/ken11/bert-japanese-ner-finetuning/blob/master/bert-japanese-ner-finetuning-tohoku.ipynb\n",
    "\n",
    "This notebook is a modified version from above link.\n",
    "The major differences are:\n",
    "- do the IOB tagging manually here, instead of calling external lib\n",
    "- convert tokenizer into TokenizerFast, in order to use newer methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "> `Remarks`: it is recommened to use virtual environment to install package instead of installing globally, if executing locally.\n",
    "You can refer to [the post here](https://code.visualstudio.com/docs/datascience/jupyter-notebooks#_setting-up-your-environment) to see how to setup environment for using jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leung.tsz.kit/Desktop/work/code/test/bert_fine_tuning_example_ner/.venv/bin/pip3\n"
     ]
    }
   ],
   "source": [
    "# TO check which pip3 you are using\n",
    "!which pip3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the transformers version is important here, because the newer version is not compatible with the TokenizerFast we use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.8/site-packages (22.0.4)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.8/site-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: transformers[ja]==4.15.0 in ./.venv/lib/python3.8/site-packages (4.15.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (1.22.3)\n",
      "Requirement already satisfied: sklearn in ./.venv/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: seqeval in ./.venv/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: sacremoses in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (0.0.53)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (0.5.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (4.64.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (6.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (2022.4.24)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (21.3)\n",
      "Requirement already satisfied: unidic>=1.0.2 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (1.1.0)\n",
      "Requirement already satisfied: fugashi>=1.0 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (1.1.2)\n",
      "Requirement already satisfied: unidic-lite>=1.0.7 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (1.0.8)\n",
      "Requirement already satisfied: ipadic<2.0,>=1.0.0 in ./.venv/lib/python3.8/site-packages (from transformers[ja]==4.15.0) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers[ja]==4.15.0) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.venv/lib/python3.8/site-packages (from packaging>=20.0->transformers[ja]==4.15.0) (3.0.8)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in ./.venv/lib/python3.8/site-packages (from unidic>=1.0.2->transformers[ja]==4.15.0) (0.9.1)\n",
      "Requirement already satisfied: plac<2.0.0,>=1.1.3 in ./.venv/lib/python3.8/site-packages (from unidic>=1.0.2->transformers[ja]==4.15.0) (1.3.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests->transformers[ja]==4.15.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests->transformers[ja]==4.15.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./.venv/lib/python3.8/site-packages (from requests->transformers[ja]==4.15.0) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests->transformers[ja]==4.15.0) (2021.10.8)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.8/site-packages (from sacremoses->transformers[ja]==4.15.0) (8.1.3)\n",
      "Requirement already satisfied: wget in ./.venv/lib/python3.8/site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install torch\n",
    "!pip3 install 'transformers[ja]==4.15.0' numpy sklearn seqeval pandas\n",
    "!pip3 install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect any GPU\n",
    "\n",
    "Below parts detect if GPU is available, and use CPU if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to avoid using GPU, change below value to False\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if use_gpu and torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('Using the CPU.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download training data\n",
    "We are using this public data : [ストックマーク株式会社が公開しているner-wikipedia-dataset](https://github.com/stockmarkteam/ner-wikipedia-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = \"./dest\"\n",
    "model_name = \"cl-tohoku/bert-base-japanese-whole-word-masking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import pprint as pp\n",
    "\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "url = \"https://github.com/stockmarkteam/ner-wikipedia-dataset/raw/main/ner.json\"\n",
    "\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "if not os.path.exists('./ner.json'):\n",
    "    wget.download(url, './ner.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"curid\": \"3572156\",\n",
      "        \"text\": \"SPRiNGSと最も仲の良いライバルグループ。\",\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"name\": \"SPRiNGS\",\n",
      "                \"span\": [\n",
      "                    0,\n",
      "                    7\n",
      "                ],\n",
      "                \"type\": \"その他の組織名\"\n",
      "            }\n",
      "        ]\n",
      "    },\n"
     ]
    }
   ],
   "source": [
    "!head -15 ner.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the data in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>流域一体は水田が多く、取水堰として樋遣川堰が設置され農業用水として利用されている一方で、同時...</td>\n",
       "      <td>[{'name': '樋遣川堰', 'span': [17, 21], 'type': '施...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>但し手続きの関係から佐藤が第5代自由民主党総裁に就任したのは12月1日であった。</td>\n",
       "      <td>[{'name': '佐藤', 'span': [10, 12], 'type': '人名'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>このアルバムの中には、ジェイク・ギレンホールについて書いた曲があるという。</td>\n",
       "      <td>[{'name': 'ジェイク・ギレンホール', 'span': [11, 22], 'ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>アメリカ合衆国において指揮活動に入り、まずはジョージ・セルに弟子入りし、その後レオポルド・ス...</td>\n",
       "      <td>[{'name': 'アメリカ合衆国', 'span': [0, 7], 'type': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>黒澤も久世も口に出すと後に引かない性格で、ついに柴山撮影所長が乗り出して、久世の殺陣が実現す...</td>\n",
       "      <td>[{'name': '黒澤', 'span': [0, 2], 'type': '人名'},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326</th>\n",
       "      <td>およびそれを利用した物品。</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>それにより、同年のJ1優勝チームである鹿島アントラーズは出場できなかった。</td>\n",
       "      <td>[{'name': 'J1', 'span': [9, 11], 'type': 'その他の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>またペスタロッチは主に初等教育分野に貢献したのに対し、彼の影響を受けたフリードリヒ・フレーベ...</td>\n",
       "      <td>[{'name': 'ペスタロッチ', 'span': [2, 8], 'type': '人...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Lions Styleはプロ野球・パシフィック・リーグの埼玉西武ライオンズの情報誌である。</td>\n",
       "      <td>[{'name': 'Lions Style', 'span': [0, 11], 'typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>その後500万以下の条件戦に5回出走するが勝利できなかった。</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "445   流域一体は水田が多く、取水堰として樋遣川堰が設置され農業用水として利用されている一方で、同時...   \n",
       "2251           但し手続きの関係から佐藤が第5代自由民主党総裁に就任したのは12月1日であった。   \n",
       "1425              このアルバムの中には、ジェイク・ギレンホールについて書いた曲があるという。   \n",
       "1448  アメリカ合衆国において指揮活動に入り、まずはジョージ・セルに弟子入りし、その後レオポルド・ス...   \n",
       "2891  黒澤も久世も口に出すと後に引かない性格で、ついに柴山撮影所長が乗り出して、久世の殺陣が実現す...   \n",
       "4326                                      およびそれを利用した物品。   \n",
       "4157              それにより、同年のJ1優勝チームである鹿島アントラーズは出場できなかった。   \n",
       "437   またペスタロッチは主に初等教育分野に貢献したのに対し、彼の影響を受けたフリードリヒ・フレーベ...   \n",
       "683       Lions Styleはプロ野球・パシフィック・リーグの埼玉西武ライオンズの情報誌である。   \n",
       "2246                     その後500万以下の条件戦に5回出走するが勝利できなかった。   \n",
       "\n",
       "                                               entities  \n",
       "445   [{'name': '樋遣川堰', 'span': [17, 21], 'type': '施...  \n",
       "2251  [{'name': '佐藤', 'span': [10, 12], 'type': '人名'...  \n",
       "1425  [{'name': 'ジェイク・ギレンホール', 'span': [11, 22], 'ty...  \n",
       "1448  [{'name': 'アメリカ合衆国', 'span': [0, 7], 'type': '...  \n",
       "2891  [{'name': '黒澤', 'span': [0, 2], 'type': '人名'},...  \n",
       "4326                                                 []  \n",
       "4157  [{'name': 'J1', 'span': [9, 11], 'type': 'その他の...  \n",
       "437   [{'name': 'ペスタロッチ', 'span': [2, 8], 'type': '人...  \n",
       "683   [{'name': 'Lions Style', 'span': [0, 11], 'typ...  \n",
       "2246                                                 []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "json_df = pd.read_json(\"./ner.json\")\n",
    "# We only need these two column\n",
    "json_df = json_df[[\"text\",\"entities\"]]\n",
    "# lets take a look some sample rows\n",
    "json_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Fine-tuning the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tokenizer from pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (From HuggingFace) There will be a warning about some of the pretrained weights not being used and some weights being randomly initialized. That’s because we are throwing away the pretraining head of the BERT model to replace it with a classification head which is randomly initialized. We will fine-tune this model on our task, transferring the knowledge of the pretrained model to it (which is why doing this is called transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# We will fine-tune the model for NER task, so we use AutoModelForTokenClassification here\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a new Tokenizer\n",
    "\n",
    "Normally we don't need a new tokenizer, but we want to try some methods only available under TokenizerFast later on.\n",
    "So we need to \"convert\" the tokenizer into a TokenizerFast.\n",
    "Read more about tokenizer base class [here](https://huggingface.co/docs/transformers/main_classes/tokenizer)\n",
    "\n",
    "Because the BertJapaneseTokenizer that we loaded cannot be converted into TokenizerFast directly.\n",
    "So we will export it into json and create a new one from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./vocab.txt',)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the vocab text.\n",
    "# Note: the model is not new enough to export a json file...\n",
    "tokenizer.save_vocabulary(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "# Build a tokenizer from vocab txt\n",
    "# Ref: https://huggingface.co/docs/tokenizers/python/latest/quicktour.html#importing-a-pretrained-tokenizer-from-legacy-vocabulary-files\n",
    "tokenizer = BertWordPieceTokenizer(\"./vocab.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert BertWordPieceTokenizer into TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "# https://huggingface.co/docs/transformers/v4.15.0/en/fast_tokenizers#loading-directly-from-the-tokenizer-object\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "# The pad token needs to be set explicitly\n",
    "fast_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the tokenization & methods\n",
    "\n",
    "This code block below is not necessary, just to show you around some values and test whether we can use methods from pretrainedTokenizerFast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the sentence:  39\n",
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      " 'input_ids': [2, 23144, 660, 632, 910, 616, 136, 259, 9, 6, 122, 751, 409, 827,\n",
      "               201, 1158, 280, 7, 108, 259, 11, 865, 609, 828, 760, 24733, 698,\n",
      "               809, 16, 16071, 8, 3],\n",
      " 'length': [32],\n",
      " 'offset_mapping': [(...), (...), (...), (...), (...), (...), (...), (...),\n",
      "                    (...), (...), (...), (...), (...), (...), (...), (...),\n",
      "                    (...), (...), (...), (...), (...), (...), (...), (...),\n",
      "                    (...), (...), (...), (...), (...), (...), (...), (...)],\n",
      " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      " ------- ------- ------- \n",
      "offset_mapping: \n",
      "[(0, 0), (0, 3), (3, 5), (5, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13),\n",
      " (13, 14)]\n",
      " ------- ------- ------- \n",
      "Original sentence :  レッドフォックス株式会社は、東京都千代田区に本社を置くITサービス企業である。\n",
      "Original sentence size:  39\n",
      " ------- ------- ------- \n",
      "token list :  ['[CLS]', 'レット', '##フォ', '##ックス', '株', '式', '会', '社', 'は', '、', '東', '京', '都', '千', '代', '田', '区', 'に', '本', '社', 'を', '置', 'く', '##it', '##サー', '##ヒス', '企', '業', 'て', '##ある', '。', '[SEP]']\n",
      "token size :  32\n",
      "input ids :  [2, 23144, 660, 632, 910, 616, 136, 259, 9, 6, 122, 751, 409, 827, 201, 1158, 280, 7, 108, 259, 11, 865, 609, 828, 760, 24733, 698, 809, 16, 16071, 8, 3]\n",
      " ------- ------- ------- \n",
      "Word index :  [None, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 20, 21, 22, 22, 23, None]\n",
      "sentence id/sequence id/token type id :  [None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None]\n",
      " ------- ------- ------- \n",
      "The character at index  22  of the sentence is  本\n",
      "Its token index is at  18  ,showing  本\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "# try\n",
    "def test(i):\n",
    "    sen = json_df[\"text\"][i]\n",
    "    print(\"Length of the sentence: \", len(sen))\n",
    "    # Tokenize a sentence\n",
    "    test_text = fast_tokenizer(sen, return_offsets_mapping=True, return_length=True)\n",
    "\n",
    "    # Let's take a look some keys returned\n",
    "    pp(test_text, depth=2, compact=True)\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    # The offset_mapping is what we will use later, to align the NER tag to tokenized text\n",
    "    print(\"offset_mapping: \")\n",
    "    pp(test_text[\"offset_mapping\"][:10], compact=True)\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    print(\"Original sentence : \", sen)\n",
    "    print(\"Original sentence size: \", len(sen))\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    # How the sentence is tokenized\n",
    "    print(\"token list : \", test_text.tokens(batch_index=0))\n",
    "    print(\"token size : \", len(test_text.tokens(batch_index=0)))\n",
    "    # The numeric representation of tokens above\n",
    "    print(\"input ids : \", test_text.input_ids)\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    # The corresponding word level index. Would be useful if your input sentence was list[Word]\n",
    "    print(\"Word index : \", test_text.word_ids(batch_index=0))\n",
    "\n",
    "    # The token type list, i.e. which sentence it belongs to, but we will not input pair of sentences here. \n",
    "    print(\"sentence id/sequence id/token type id : \", test_text.sequence_ids(batch_index=0))\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    # Below shows how to do some converting\n",
    "    char_i = 22\n",
    "    print(\"The character at index \", char_i, \" of the sentence is \", sen[char_i])\n",
    "    print(\"Its token index is at \", test_text.char_to_token(0, char_i), \" ,showing \", test_text.tokens(batch_index=0)[test_text.char_to_token(0, char_i)])\n",
    "\n",
    "\n",
    "# Test with a sentence from json_df\n",
    "test(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data pre-processing\n",
    "\n",
    "The raw data & annotation is like below:\n",
    "\n",
    "- Original sentence:  \n",
    "    ```\n",
    "    レッドフォックス株式会社は、東京都千代田区に本社を置くITサービス企業である。\n",
    "    ```\n",
    "\n",
    "- Original sentence size:  \n",
    "    ```\n",
    "    39\n",
    "    ```\n",
    "\n",
    "- Original label (json_df[\"entities\"][0]): \n",
    "    ```python\n",
    "    [\n",
    "        {'name': 'レッドフォックス株式会社', 'span': [0, 12], 'type': '法人名'},\n",
    "        {'name': '東京都千代田区', 'span': [14, 21], 'type': '地名'}\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "We would like to convert it into below form (IOB format) that is easier to process later.\n",
    "\n",
    "- Desired label structure (for 1 sentence):  \n",
    "    (list with the same size as the original sentence )\n",
    "    ```python\n",
    "    ['B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'O', 'B-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "    ```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'レッドフォックス株式会社', 'span': [0, 12], 'type': '法人名'},\n",
       " {'name': '東京都千代田区', 'span': [14, 21], 'type': '地名'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the sample of record\n",
    "json_df[\"entities\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an important step, that we modify the y label, and convert into IOB tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER tag set :  {'B-その他の組織名', 'B-製品名', 'I-地名', 'B-政治的組織名', 'I-政治的組織名', 'B-地名', 'I-人名', 'I-その他の組織名', 'I-施設名', 'B-人名', 'B-イベント名', 'O', 'I-製品名', 'I-イベント名', 'B-法人名', 'I-法人名', 'B-施設名'}\n",
      "a row of structured list : \n",
      "{'label': ['B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名',\n",
      "           'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'O', 'B-地名',\n",
      "           'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'O', 'O',\n",
      "           'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "           'O'],\n",
      " 'text': 'レッドフォックス株式会社は、東京都千代田区に本社を置くITサービス企業である。'}\n",
      "The length of this label :  39\n",
      "The length of this sentence :  39\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "## 1. Convert the raw annotation into desired label structure for model training\n",
    "##    i.e. Restructure json_df[\"entities\"] into the same shape of sentence\n",
    "## 2. Build the NER tag mapping\n",
    "\n",
    "\n",
    "# We will use IOB tagging scheme\n",
    "# It will temporarily store the unique value of all labels\n",
    "ner_tag_set = set()\n",
    "# Add O <-- others\n",
    "ner_tag_set.add(\"O\")\n",
    "# We only need list structure from now on. Pandas is not good at looping row.\n",
    "json_list = json_df.to_dict('records')\n",
    "\n",
    "for index, row in enumerate(json_list):\n",
    "    # For each sentence at [index]\n",
    "    # e.g. row: { text: xxxx, entities: [...]}\n",
    "\n",
    "    # Form the label list as same size as the length of sentence, filled with O\n",
    "    label_list = [\"O\"] * len(row[\"text\"])\n",
    "    for entity in row[\"entities\"]:\n",
    "        # For each annotation data for this sentence\n",
    "        # e.g {'name': 'SPRiNGS', 'span': [0, 7], 'type': 'その他の組織名'}\n",
    "\n",
    "        ## Add 2 variants to dictionary set for future use\n",
    "        ner_tag_set.add(\"B-\" + entity[\"type\"])\n",
    "        ner_tag_set.add(\"I-\" + entity[\"type\"])\n",
    "\n",
    "        # the label location index at sentence\n",
    "        start = entity[\"span\"][0]\n",
    "        end = entity[\"span\"][1]\n",
    "\n",
    "        # set the label in label_list\n",
    "        label_list[start] = \"B-\" + entity[\"type\"]\n",
    "        label_list[start+1:end+1] = [\"I-\" + entity[\"type\"]] * (end - start) # the remained 1 is assigned in next line\n",
    "\n",
    "    # put it in the json_list\n",
    "    row[\"label\"] = label_list\n",
    "    # we don't need this anymore\n",
    "    del row[\"entities\"]\n",
    "\n",
    "\n",
    "print(\"NER tag set : \", ner_tag_set)\n",
    "print(\"a row of structured list : \")\n",
    "pp(json_list[1], compact=True)\n",
    "print(\"The length of this label : \", len(json_list[1][\"label\"]))\n",
    "print(\"The length of this sentence : \", len(json_list[1][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_tag_map with size:  17\n",
      "{'B-その他の組織名': 0, 'B-イベント名': 1, 'B-人名': 2, 'B-地名': 3, 'B-政治的組織名': 4, 'B-施設名': 5, 'B-法人名': 6, 'B-製品名': 7, 'I-その他の組織名': 8, 'I-イベント名': 9, 'I-人名': 10, 'I-地名': 11, 'I-政治的組織名': 12, 'I-施設名': 13, 'I-法人名': 14, 'I-製品名': 15, 'O': 16}\n",
      "{0: 'B-その他の組織名', 1: 'B-イベント名', 2: 'B-人名', 3: 'B-地名', 4: 'B-政治的組織名', 5: 'B-施設名', 6: 'B-法人名', 7: 'B-製品名', 8: 'I-その他の組織名', 9: 'I-イベント名', 10: 'I-人名', 11: 'I-地名', 12: 'I-政治的組織名', 13: 'I-施設名', 14: 'I-法人名', 15: 'I-製品名', 16: 'O'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## prepare the id to list, list to id mapper\n",
    "## They will be used in configuration of trainer\n",
    "## For the official doc, ref to https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig\n",
    "ner_tag_map = list(ner_tag_set)\n",
    "ner_tag_map.sort()\n",
    "print(\"ner_tag_map with size: \", len(ner_tag_map))\n",
    "\n",
    "label2id = { label: i for i, label in enumerate(ner_tag_map)}\n",
    "print(label2id)\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "print(id2label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into 3 sets: `train`, `valid`, `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(json_list, test_size=0.2, random_state=123)\n",
    "train_data, test_data = train_test_split(train_data, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "            'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "            'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "            'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-人名', 'I-人名', 'I-人名',\n",
      "            'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'O', 'O', 'O'],\n",
      "  'text': '公式サイトは、2004年11月1日にリニューアルされており、デザインを担当したのはデザイナーのタケウエトモコである。'}]\n"
     ]
    }
   ],
   "source": [
    "## Lets check the train data\n",
    "pp(train_data[:1], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained model\n",
    "Load the pre-trained model and store the `label2id`, `id2label` we created from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(model_name, label2id=label2id, id2label=id2label)\n",
    "model = BertForTokenClassification.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# We could take a look some details of the model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for the training\n",
    "Setup the TrainingArguments and Trainer with data_collator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_collator is for the trainer to load the data. [More here](https://huggingface.co/docs/transformers/main_classes/data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# This data_collator will be used by the trainer\n",
    "# and as a preprocess method when we do evaulation later.\n",
    "def data_collator(features: list) -> dict:\n",
    "    \"\"\"\n",
    "    The purpose of this method, is to tokenize the train data,\n",
    "    so we get all the required input(e.g. numeric tokens, attendence mask, ...etc)\n",
    "    Also we re-align the labels of sentences into labels of tokens,\n",
    "    according to the tokenized list. \n",
    "    \"\"\"\n",
    "    # Lets just use 64 as max length for simplicity\n",
    "    max_len = 64\n",
    "    tokenized_list = []\n",
    "    ## tokenized all text, while aligning the label list to match the result text\n",
    "    for index, row in enumerate(features):\n",
    "        # For each row at [index], e.g. { \"label\": [xxx], \"text\": \"xxxx\" }\n",
    "\n",
    "        # The return_offsets_mapping is so important here\n",
    "        # so that we can use it to re-align the labels\n",
    "        # The return_length let us know the length of the tokenized sentence (including CLS, SEP)\n",
    "        fast_result = fast_tokenizer(row[\"text\"], return_tensors=None, padding='max_length', \n",
    "                                    truncation=True, max_length=max_len, return_offsets_mapping=True,\n",
    "                                    return_length=True)\n",
    "\n",
    "        ## Build the aligned label list with prefilled values\n",
    "        ## The length here is same as tokens length in one sentence\n",
    "        ## NOTE: it includes special token [CLS][SEP][PAD]\n",
    "        y_each_sentence = [ -100 ] * len(fast_result.offset_mapping)\n",
    "\n",
    "        ## 'offset_mapping': [(0, 0), (0, 3), (3, 5), (5, 8), (8, 9), ...]\n",
    "        for index, offset_tuple in enumerate(fast_result.offset_mapping):\n",
    "            ## It is [PAD] already, break loop to save time\n",
    "            if index >= fast_result.length[0] :\n",
    "                break\n",
    "            ## If it is special token [CLS], [SEP] or [PAD], leave it as -100\n",
    "            if offset_tuple == (0, 0) : \n",
    "                continue\n",
    "            # Using our structured label list, get the annotation(its id value)\n",
    "            ## reminder: ['B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', ... ]\n",
    "            target_label = row[\"label\"][offset_tuple[0]] # e.g. 'B-法人名'\n",
    "            target_label_id = label2id[target_label] # e.g. 2\n",
    "            y_each_sentence[index] = target_label_id\n",
    "        \n",
    "        fast_result[\"labels\"] = y_each_sentence\n",
    "        # Remove unnecessary field, otherwise model training will throw error\n",
    "        del fast_result[\"offset_mapping\"]\n",
    "        del fast_result[\"length\"]\n",
    "        tokenized_list.append(fast_result)\n",
    "\n",
    "    # transpose\n",
    "    df_all = pd.DataFrame(tokenized_list)\n",
    "    dict_filter = df_all.to_dict(orient=\"list\")\n",
    "    # Convert all input to tensor, and put to specific CPU/GPU\n",
    "    batch = {k: torch.tensor(v, dtype=torch.int64).to(device) for k, v in dict_filter.items()}\n",
    "    return batch\n",
    "\n",
    "    # print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
      " 'input_ids': tensor([[    2, 11619, 24501, 28589, 28452,   113,    28,  1883,     5,  1273,\n",
      "            21,   415, 12246, 25457, 28503,     8,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]),\n",
      " 'labels': tensor([[-100,    0,    8,    8,    8,   16,   16,   16,   16,   16,   16,   16,\n",
      "           16,   16,   16,   16, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100]]),\n",
      " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "## lets test it before using in training\n",
    "a = data_collator(json_list[:1])\n",
    "pp(a, compact=True, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training !\n",
    "\n",
    "We will define some hyperparameters with TrainingArguments class, which will be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"./ckpt\"\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "learning_rate = 3e-5\n",
    "save_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(output_dir=ckpt_dir,\n",
    "                         do_train=True,\n",
    "                         do_eval=True,\n",
    "                         do_predict=True,\n",
    "                         per_device_train_batch_size=batch_size,\n",
    "                         per_device_eval_batch_size=batch_size,\n",
    "                         learning_rate=learning_rate,\n",
    "                         num_train_epochs=epochs,\n",
    "                         evaluation_strategy=\"steps\",\n",
    "                         eval_steps=save_freq,\n",
    "                         save_strategy=\"steps\",\n",
    "                         save_steps=save_freq,\n",
    "                         load_best_model_at_end=True,\n",
    "                         dataloader_pin_memory=False, #Important if you use gpu\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is to move the model to GPU (or cpu defined above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we finally can define the Trainer, with:\n",
    "- training data\n",
    "- evaluation data\n",
    "- data collator method\n",
    "- Training arguments\n",
    "- Loaded pre-trained model\n",
    "- Early stop strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  data_collator=data_collator,\n",
    "                  train_dataset=train_data,\n",
    "                  eval_dataset=val_data,\n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a trained model now. Let's try to use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 428\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.25463199615478516, 'test_runtime': 1.5567, 'test_samples_per_second': 274.945, 'test_steps_per_second': 17.345}\n"
     ]
    }
   ],
   "source": [
    "_, _, metrics = trainer.predict(test_data, metric_key_prefix=\"test\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to save the model into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./dest\n",
      "Configuration saved in ./dest/config.json\n",
      "Model weights saved in ./dest/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "We will use [seqeval](https://github.com/chakki-works/seqeval) here to test the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論用の関数を定義\n",
    "学習したモデルを使って推論をするための関数を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'entities', 'label'])\n",
      "{'text': '若き科学者ハンク・マッコイはブランドコーポレーションで働き、ミューテーションの誘発物質を分離させる事ができた。', 'entities': [{'name': 'ハンク・マッコイ', 'span': [5, 13], 'type': '人名'}, {'name': 'ブランドコーポレーション', 'span': [14, 26], 'type': '法人名'}], 'label': ['O', 'O', 'O', 'O', 'O', 'B-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "# Recall how does the test data look like\n",
    "print(test_data[0].keys())\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the data collator from above, to process the test data for evalution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the function convert the train dataset into tokenized input for model, also align the label for comparing later\n",
    "def preprocess(each_dict: dict) -> dict:\n",
    "    # lets reuse the data_collator from above to do tokenization & label structuring\n",
    "    batch_dict = data_collator([each_dict])\n",
    "    return  batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'),\n",
      " 'input_ids': tensor([[    2,  1099,   322,   536,   112,   104,  2777, 28488,    35, 27492,\n",
      "         20418, 28450,  4536, 28476,  1551, 28774,  2260, 28456,  2131,   322,\n",
      "             6,  8826,  6977, 28444,  2325,    85,   410,  2015,    11,   155,\n",
      "          1022,  9293,   146,    29, 28456, 28512, 28447,     8,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]], device='cuda:0'),\n",
      " 'labels': tensor([[-100,   16,   16,   16,   16,   16,    2,   10,   10,   10,   10,   10,\n",
      "            6,   14,   14,   14,   14,   14,   16,   16,   16,   16,   16,   16,\n",
      "           16,   16,   16,   16,   16,   16,   16,   16,   16,   16,   16,   16,\n",
      "           16,   16, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100]], device='cuda:0'),\n",
      " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}\n",
      "tokenized sentence size (including CLS,SEP) :  39\n"
     ]
    }
   ],
   "source": [
    "## Lets try first\n",
    "tmp_test_after_preprocess = preprocess(test_data[0])\n",
    "pp.pprint(tmp_test_after_preprocess)\n",
    "print(\"tokenized sentence size (including CLS,SEP) : \", np.sum(tmp_test_after_preprocess[\"attention_mask\"][0].cpu().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the stored model, and put to gpu (or cpu)\n",
    "Also we define the inference method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./dest/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\",\n",
      "    \"1\": \"B-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\",\n",
      "    \"2\": \"B-\\u4eba\\u540d\",\n",
      "    \"3\": \"B-\\u5730\\u540d\",\n",
      "    \"4\": \"B-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\",\n",
      "    \"5\": \"B-\\u65bd\\u8a2d\\u540d\",\n",
      "    \"6\": \"B-\\u6cd5\\u4eba\\u540d\",\n",
      "    \"7\": \"B-\\u88fd\\u54c1\\u540d\",\n",
      "    \"8\": \"I-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\",\n",
      "    \"9\": \"I-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\",\n",
      "    \"10\": \"I-\\u4eba\\u540d\",\n",
      "    \"11\": \"I-\\u5730\\u540d\",\n",
      "    \"12\": \"I-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\",\n",
      "    \"13\": \"I-\\u65bd\\u8a2d\\u540d\",\n",
      "    \"14\": \"I-\\u6cd5\\u4eba\\u540d\",\n",
      "    \"15\": \"I-\\u88fd\\u54c1\\u540d\",\n",
      "    \"16\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\": 0,\n",
      "    \"B-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\": 1,\n",
      "    \"B-\\u4eba\\u540d\": 2,\n",
      "    \"B-\\u5730\\u540d\": 3,\n",
      "    \"B-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\": 4,\n",
      "    \"B-\\u65bd\\u8a2d\\u540d\": 5,\n",
      "    \"B-\\u6cd5\\u4eba\\u540d\": 6,\n",
      "    \"B-\\u88fd\\u54c1\\u540d\": 7,\n",
      "    \"I-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\": 8,\n",
      "    \"I-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\": 9,\n",
      "    \"I-\\u4eba\\u540d\": 10,\n",
      "    \"I-\\u5730\\u540d\": 11,\n",
      "    \"I-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\": 12,\n",
      "    \"I-\\u65bd\\u8a2d\\u540d\": 13,\n",
      "    \"I-\\u6cd5\\u4eba\\u540d\": 14,\n",
      "    \"I-\\u88fd\\u54c1\\u540d\": 15,\n",
      "    \"O\": 16\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ./dest/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./dest.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import BertForTokenClassification\n",
    "\n",
    "inference_model = BertForTokenClassification.from_pretrained(model_output_dir)\n",
    "inference_model.to(device)\n",
    "def inference(each_line_dict: dict) -> list:\n",
    "\n",
    "    input_dict = preprocess(each_line_dict)\n",
    "    # dict_keys(['attention_mask', 'input_ids', 'token_type_ids', 'labels'])\n",
    "    del input_dict['labels']\n",
    "    # Get tokenized sentence size\n",
    "    tokenized_length = np.sum(input_dict[\"attention_mask\"][0].cpu().tolist())\n",
    "\n",
    "    # Inference !\n",
    "    pred = inference_model(**input_dict).logits[0]\n",
    "    # print(np.shape(pred)) # torch.Size([64, 17])\n",
    "    pred = np.argmax(pred.cpu().detach().numpy(), axis=-1)\n",
    "    labels = []\n",
    "    for i, label in enumerate(pred):\n",
    "        # The last meaningful element is also a special token [SEP], so we ignore it\n",
    "        if i >= (tokenized_length-1): break\n",
    "        labels.append(inference_model.config.id2label[label])\n",
    "        # labels[i] = label\n",
    "    # Remove 1st element, which is [CLS]\n",
    "    labels.pop(0)\n",
    "    return pred[1:(tokenized_length-1)], labels\n",
    "    # return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value: \n",
      "array([16, 16,  6, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "       16, 16, 16,  6, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "       16, 16])\n",
      "36\n",
      "--------\n",
      "Converted to label: \n",
      "['O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Lets test it\n",
    "temp_test_pred, temp_test_labels = inference(test_data[2])\n",
    "print(\"Prediction value: \")\n",
    "pp.pprint(temp_test_pred, compact=True)\n",
    "print(len(temp_test_pred))\n",
    "print(\"--------\")\n",
    "print(\"Converted to label: \")\n",
    "pp.pprint(temp_test_labels, compact=True)\n",
    "print(len(temp_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation, we need to preprocess the label as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "36\n",
      "(428,)\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "y_true = []\n",
    "for unit in test_data :\n",
    "    batch_dict = preprocess(unit)\n",
    "    tokenized_length = np.sum(batch_dict[\"attention_mask\"][0].cpu().tolist())\n",
    "    ylist = batch_dict[\"labels\"].tolist() \n",
    "\n",
    "    ylist = [ inference_model.config.id2label[eachVal if eachVal >= 0 else 16] for eachVal in ylist[0] ]\n",
    "    y_true.append(ylist[1:(tokenized_length-1)])\n",
    "\n",
    "pp.pprint(y_true[2], compact=True)\n",
    "print(len(y_true[2]))\n",
    "print(np.shape(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do inference on the whole test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'B-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名',\n",
      "  'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
      " ['B-人名', 'I-人名', 'I-人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-地名', 'I-地名', 'I-地名', 'O', 'O', 'O',\n",
      "  'O', 'B-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'O', 'O', 'O', 'O', 'O', 'O', 'B-地名', 'I-地名', 'I-地名', 'O', 'O',\n",
      "  'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for unit in test_data:\n",
    "    temp_test_pred, temp_test_label = inference(unit)\n",
    "    y_pred.append(temp_test_label)\n",
    "pp.pprint(y_pred[:2], compact=True, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seqeval - classification_report\n",
    "We can evaluate by classification_report in seqeval lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     その他の組織名       0.52      0.74      0.61        68\n",
      "       イベント名       0.73      0.79      0.76        73\n",
      "          人名       0.87      0.89      0.88       248\n",
      "          地名       0.74      0.78      0.76       172\n",
      "      政治的組織名       0.66      0.76      0.71        85\n",
      "         施設名       0.60      0.74      0.66        72\n",
      "         法人名       0.65      0.79      0.71       214\n",
      "         製品名       0.59      0.65      0.62       102\n",
      "\n",
      "   micro avg       0.70      0.79      0.74      1034\n",
      "   macro avg       0.67      0.77      0.71      1034\n",
      "weighted avg       0.71      0.79      0.74      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "from seqeval.scheme import BILOU\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "# You can also specify the tagging scheme if you are using something else\n",
    "#print(classification_report(y_true, y_pred, mode='strict', scheme=BILOU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "If only for inference without the need to evaluate, we can use the code below.\n",
    "But keep in mind that it is not optimized for production use case yet.\n",
    "\n",
    "For example,\n",
    "- consider to store the loaded model/tokenizer into memory/singleton class for quicker response in the future usage\n",
    "- deal with the case if input text is too long, e.g. split into chunks\n",
    "- use onnx instead of the plain model to speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "def inference(text: str):\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_output_dir)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=64)\n",
    "    tokenized_length = np.sum(inputs[\"attention_mask\"][0].cpu().tolist())\n",
    "    pred = model(**inputs).logits[0]\n",
    "    pred = np.argmax(pred.detach().numpy(), axis=-1)\n",
    "    labels = []\n",
    "    for i, label in enumerate(pred):\n",
    "        if i > (tokenized_length-1): break\n",
    "        labels.append(inference_model.config.id2label[label])\n",
    "    labels.pop(0)\n",
    "    print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].cpu().tolist()))\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./dest/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./dest\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\",\n",
      "    \"1\": \"B-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\",\n",
      "    \"2\": \"B-\\u4eba\\u540d\",\n",
      "    \"3\": \"B-\\u5730\\u540d\",\n",
      "    \"4\": \"B-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\",\n",
      "    \"5\": \"B-\\u65bd\\u8a2d\\u540d\",\n",
      "    \"6\": \"B-\\u6cd5\\u4eba\\u540d\",\n",
      "    \"7\": \"B-\\u88fd\\u54c1\\u540d\",\n",
      "    \"8\": \"I-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\",\n",
      "    \"9\": \"I-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\",\n",
      "    \"10\": \"I-\\u4eba\\u540d\",\n",
      "    \"11\": \"I-\\u5730\\u540d\",\n",
      "    \"12\": \"I-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\",\n",
      "    \"13\": \"I-\\u65bd\\u8a2d\\u540d\",\n",
      "    \"14\": \"I-\\u6cd5\\u4eba\\u540d\",\n",
      "    \"15\": \"I-\\u88fd\\u54c1\\u540d\",\n",
      "    \"16\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\": 0,\n",
      "    \"B-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\": 1,\n",
      "    \"B-\\u4eba\\u540d\": 2,\n",
      "    \"B-\\u5730\\u540d\": 3,\n",
      "    \"B-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\": 4,\n",
      "    \"B-\\u65bd\\u8a2d\\u540d\": 5,\n",
      "    \"B-\\u6cd5\\u4eba\\u540d\": 6,\n",
      "    \"B-\\u88fd\\u54c1\\u540d\": 7,\n",
      "    \"I-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\": 8,\n",
      "    \"I-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\": 9,\n",
      "    \"I-\\u4eba\\u540d\": 10,\n",
      "    \"I-\\u5730\\u540d\": 11,\n",
      "    \"I-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\": 12,\n",
      "    \"I-\\u65bd\\u8a2d\\u540d\": 13,\n",
      "    \"I-\\u6cd5\\u4eba\\u540d\": 14,\n",
      "    \"I-\\u88fd\\u54c1\\u540d\": 15,\n",
      "    \"O\": 16\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ./dest/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./dest.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/vocab.txt from cache at /home/jupyter/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/tokenizer_config.json from cache at /home/jupyter/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/tokenizer.json from cache at None\n",
      "loading configuration file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '田中', 'さん', 'の', '会社', 'の', '社長', 'は', '鈴木', 'さん', 'です', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "['B-人名', 'I-人名', 'O', 'O', 'O', 'O', 'O', 'B-人名', 'I-人名', 'O', 'O']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(inference(\"田中さんの会社の社長は鈴木さんです\"))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "interpreter": {
   "hash": "c4ade181237a227d1e6bc9e7cc52b7e8773cedb0849c87f4312e88791c849335"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
