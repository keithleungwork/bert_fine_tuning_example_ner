{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 東北大BERTをベースにファインチューニングで固有表現抽出用モデルを作成する\n",
    "huggingfaceで公開されている東北大BERTこと `cl-tohoku/bert-base-japanese-whole-word-masking` をベースに、ファインチューニングをして固有表現抽出タスク用のモデルを作成します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Originated from https://github.com/ken11/bert-japanese-ner-finetuning/blob/master/bert-japanese-ner-finetuning-tohoku.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインストール\n",
    "必要なライブラリをインストールします\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> remarks2: it is recommened to use virtual environment to install package instead of installing globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/jupyter/anaconda3/envs/bertbersamplekento/bin/pip3\r\n"
     ]
    }
   ],
   "source": [
    "# TO check which pip3 you are using\n",
    "!which pip3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> remarks: transformers need to be at this version. 4.16.0 was tried but error will happen later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: pip in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (22.0.2)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers[ja]==4.15.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (4.15.0)\n",
      "Requirement already satisfied: numpy in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (1.20.3)\n",
      "Requirement already satisfied: sklearn in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: seqeval in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (1.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (2021.8.3)\n",
      "Requirement already satisfied: requests in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (2.26.0)\n",
      "Requirement already satisfied: filelock in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (3.3.1)\n",
      "Requirement already satisfied: sacremoses in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (0.0.47)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (0.4.0)\n",
      "Requirement already satisfied: unidic>=1.0.2 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (1.1.0)\n",
      "Requirement already satisfied: unidic-lite>=1.0.7 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (1.0.8)\n",
      "Requirement already satisfied: fugashi>=1.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (1.1.1)\n",
      "Requirement already satisfied: ipadic<2.0,>=1.0.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from transformers[ja]==4.15.0) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers[ja]==4.15.0) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from packaging>=20.0->transformers[ja]==4.15.0) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from unidic>=1.0.2->transformers[ja]==4.15.0) (0.9.0)\n",
      "Requirement already satisfied: plac<2.0.0,>=1.1.3 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from unidic>=1.0.2->transformers[ja]==4.15.0) (1.3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from requests->transformers[ja]==4.15.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from requests->transformers[ja]==4.15.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from requests->transformers[ja]==4.15.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from requests->transformers[ja]==4.15.0) (2021.10.8)\n",
      "Requirement already satisfied: six in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from sacremoses->transformers[ja]==4.15.0) (1.16.0)\n",
      "Requirement already satisfied: click in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from sacremoses->transformers[ja]==4.15.0) (8.0.3)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from torch==1.9.0+cu111) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from torchvision==0.10.0+cu111) (1.20.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (from torchvision==0.10.0+cu111) (8.4.0)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: wget in /home/jupyter/anaconda3/envs/bertbersamplekento/lib/python3.9/site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pip\n",
    "!pip3 install transformers[\"ja\"]==4.15.0 numpy sklearn seqeval\n",
    "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip3 install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = \"./dest\"\n",
    "model_name = \"cl-tohoku/bert-base-japanese-whole-word-masking\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup GPU (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to avoid using GPU, change below value to False\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if use_gpu and torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('Using the CPU.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データのダウンロード\n",
    "今回は[ストックマーク株式会社が公開しているner-wikipedia-dataset](https://github.com/stockmarkteam/ner-wikipedia-dataset)を利用させていただきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import pprint as pp\n",
    "\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "url = \"https://github.com/stockmarkteam/ner-wikipedia-dataset/raw/main/ner.json\"\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "if not os.path.exists('./ner.json'):\n",
    "    wget.download(url, './ner.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードした学習データを確認してみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"curid\": \"3572156\",\n",
      "        \"text\": \"SPRiNGSと最も仲の良いライバルグループ。\",\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"name\": \"SPRiNGS\",\n",
      "                \"span\": [\n",
      "                    0,\n",
      "                    7\n",
      "                ],\n",
      "                \"type\": \"その他の組織名\"\n",
      "            }\n",
      "        ]\n",
      "    },\n"
     ]
    }
   ],
   "source": [
    "!head -15 ner.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実行\n",
    "実際に学習を行っていきます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizerの準備\n",
    "Tokenizerを用意します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (From HuggingFace) There will be a warning about some of the pretrained weights not being used and some weights being randomly initialized. That’s because we are throwing away the pretraining head of the BERT model to replace it with a classification head which is randomly initialized. We will fine-tune this model on our task, transferring the knowledge of the pretrained model to it (which is why doing this is called transfer learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# We will fine-tune the model for NER task, so we use AutoModelForTokenClassification here\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データの前処理\n",
    "先ほどダウンロードしてきた学習データを、学習に使えるように前処理していきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>そしてクライスラー製の313 in3V8エンジンの採用を決めた。</td>\n",
       "      <td>[{'name': 'クライスラー', 'span': [3, 9], 'type': '法...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>最終的には自由党が民主党の党役員・政策を継承することで菅直人代表と小沢党首が合意し、7月23...</td>\n",
       "      <td>[{'name': '自由党', 'span': [5, 8], 'type': '政治的組...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>なおカラー版と並行して撮影されたモノクロ版は、映画公開後に破棄されたものと長らく思われていた...</td>\n",
       "      <td>[{'name': '木下惠介', 'span': [48, 52], 'type': '人...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>2006 FIFAワールドカップの欧州予選では8ゴールを奪い本大会でも注目の存在だったが、怪...</td>\n",
       "      <td>[{'name': '2006 FIFAワールドカップ', 'span': [0, 16],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>御嶽山の西側、濁河温泉は7合目、湯屋温泉と下島温泉はふもとにあり、いずれも渓谷沿いの自然豊か...</td>\n",
       "      <td>[{'name': '御嶽山', 'span': [0, 3], 'type': '地名'}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>このことについて海洋堂の宮脇修一専務は、中国の人件費高騰や不況による市場縮小などが原因である...</td>\n",
       "      <td>[{'name': '海洋堂', 'span': [8, 11], 'type': '法人名...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>しかし、試合出場は無く1年で戦力外となり、翌2006年に発足したばかりのツエーゲン金沢に移籍。</td>\n",
       "      <td>[{'name': 'ツエーゲン金沢', 'span': [36, 43], 'type':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>アンドモワ株式会社は、日本の外食チェーンストア。</td>\n",
       "      <td>[{'name': 'アンドモワ株式会社', 'span': [0, 9], 'type':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>中部オープンゴルフ選手権競技は、中部ゴルフ連盟主催で1971年から開催されているゴルフトーナ...</td>\n",
       "      <td>[{'name': '中部オープンゴルフ選手権競技', 'span': [0, 14], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>このことはオークハーバーの北にウィドビー島海軍航空基地があることが関与している。</td>\n",
       "      <td>[{'name': 'オークハーバー', 'span': [5, 12], 'type': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "5127                   そしてクライスラー製の313 in3V8エンジンの採用を決めた。   \n",
       "987   最終的には自由党が民主党の党役員・政策を継承することで菅直人代表と小沢党首が合意し、7月23...   \n",
       "4612  なおカラー版と並行して撮影されたモノクロ版は、映画公開後に破棄されたものと長らく思われていた...   \n",
       "966   2006 FIFAワールドカップの欧州予選では8ゴールを奪い本大会でも注目の存在だったが、怪...   \n",
       "3787  御嶽山の西側、濁河温泉は7合目、湯屋温泉と下島温泉はふもとにあり、いずれも渓谷沿いの自然豊か...   \n",
       "2744  このことについて海洋堂の宮脇修一専務は、中国の人件費高騰や不況による市場縮小などが原因である...   \n",
       "4193    しかし、試合出場は無く1年で戦力外となり、翌2006年に発足したばかりのツエーゲン金沢に移籍。   \n",
       "1152                           アンドモワ株式会社は、日本の外食チェーンストア。   \n",
       "1829  中部オープンゴルフ選手権競技は、中部ゴルフ連盟主催で1971年から開催されているゴルフトーナ...   \n",
       "4048           このことはオークハーバーの北にウィドビー島海軍航空基地があることが関与している。   \n",
       "\n",
       "                                               entities  \n",
       "5127  [{'name': 'クライスラー', 'span': [3, 9], 'type': '法...  \n",
       "987   [{'name': '自由党', 'span': [5, 8], 'type': '政治的組...  \n",
       "4612  [{'name': '木下惠介', 'span': [48, 52], 'type': '人...  \n",
       "966   [{'name': '2006 FIFAワールドカップ', 'span': [0, 16],...  \n",
       "3787  [{'name': '御嶽山', 'span': [0, 3], 'type': '地名'}...  \n",
       "2744  [{'name': '海洋堂', 'span': [8, 11], 'type': '法人名...  \n",
       "4193  [{'name': 'ツエーゲン金沢', 'span': [36, 43], 'type':...  \n",
       "1152  [{'name': 'アンドモワ株式会社', 'span': [0, 9], 'type':...  \n",
       "1829  [{'name': '中部オープンゴルフ選手権競技', 'span': [0, 14], '...  \n",
       "4048  [{'name': 'オークハーバー', 'span': [5, 12], 'type': ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "json_df = pd.read_json(\"./ner.json\")\n",
    "# We only need these two column\n",
    "json_df = json_df[[\"text\",\"entities\"]]\n",
    "# lets take a look some sample rows\n",
    "json_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a new Tokenizer\n",
    "This Step is important, because the BertJapaneseTokenizer cannot be converted into TokenizerFast.\n",
    "But we will need to use some TokenizerFast exclusive methods later.\n",
    "\n",
    "Strictly speaking, the methods are exclusive to the output of a PreTrainedTokenizerFast, read more [here](https://huggingface.co/docs/transformers/v4.15.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./vocab.txt',)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the vocab text.\n",
    "# Note: the model is not new enough to export a json file...\n",
    "tokenizer.save_vocabulary(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "# Build a tokenizer from vocab txt\n",
    "# Ref: https://huggingface.co/docs/tokenizers/python/latest/quicktour.html#importing-a-pretrained-tokenizer-from-legacy-vocabulary-files\n",
    "tokenizer = BertWordPieceTokenizer(\"./vocab.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tokenizer into TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "# https://huggingface.co/docs/transformers/v4.15.0/en/fast_tokenizers#loading-directly-from-the-tokenizer-object\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "# The pad token needs to be set explicitly\n",
    "fast_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the tokenization & methods\n",
    "\n",
    "This code block below is not necessary, just to show you some values around and whether the tokenizer can use methods from pretrainedTokenizerFast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the sentence:  39\n",
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      " 'input_ids': [2, 23144, 660, 632, 910, 616, 136, 259, 9, 6, 122, 751, 409, 827,\n",
      "               201, 1158, 280, 7, 108, 259, 11, 865, 609, 828, 760, 24733, 698,\n",
      "               809, 16, 16071, 8, 3],\n",
      " 'length': [32],\n",
      " 'offset_mapping': [(...), (...), (...), (...), (...), (...), (...), (...),\n",
      "                    (...), (...), (...), (...), (...), (...), (...), (...),\n",
      "                    (...), (...), (...), (...), (...), (...), (...), (...),\n",
      "                    (...), (...), (...), (...), (...), (...), (...), (...)],\n",
      " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      " ------- ------- ------- \n",
      "offset_mapping: \n",
      "[(0, 0), (0, 3), (3, 5), (5, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13),\n",
      " (13, 14)]\n",
      " ------- ------- ------- \n",
      "Original sentence :  レッドフォックス株式会社は、東京都千代田区に本社を置くITサービス企業である。\n",
      "Original sentence size:  39\n",
      " ------- ------- ------- \n",
      "token list :  ['[CLS]', 'レット', '##フォ', '##ックス', '株', '式', '会', '社', 'は', '、', '東', '京', '都', '千', '代', '田', '区', 'に', '本', '社', 'を', '置', 'く', '##it', '##サー', '##ヒス', '企', '業', 'て', '##ある', '。', '[SEP]']\n",
      "token size :  32\n",
      "input ids :  [2, 23144, 660, 632, 910, 616, 136, 259, 9, 6, 122, 751, 409, 827, 201, 1158, 280, 7, 108, 259, 11, 865, 609, 828, 760, 24733, 698, 809, 16, 16071, 8, 3]\n",
      " ------- ------- ------- \n",
      "Word index :  [None, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 20, 21, 22, 22, 23, None]\n",
      "sentence id/sequence id/token type id :  [None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None]\n",
      " ------- ------- ------- \n",
      "The character at index  22  of the sentence is  本\n",
      "Its token index is at  18  ,showing  本\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "# try\n",
    "def test(i):\n",
    "    sen = json_df[\"text\"][i]\n",
    "    print(\"Length of the sentence: \", len(sen))\n",
    "    # Tokenize a sentence\n",
    "    test_text = fast_tokenizer(sen, return_offsets_mapping=True, return_length=True)\n",
    "\n",
    "    # Let's take a look some keys returned\n",
    "    pp(test_text, depth=2, compact=True)\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    # The offset_mapping is what we will use later, to align the NER tag to tokenized text\n",
    "    print(\"offset_mapping: \")\n",
    "    pp(test_text[\"offset_mapping\"][:10], compact=True)\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    print(\"Original sentence : \", sen)\n",
    "    print(\"Original sentence size: \", len(sen))\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    # How the sentence is tokenized\n",
    "    print(\"token list : \", test_text.tokens(batch_index=0))\n",
    "    print(\"token size : \", len(test_text.tokens(batch_index=0)))\n",
    "    # The numeric representation of tokens above\n",
    "    print(\"input ids : \", test_text.input_ids)\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    # The corresponding word level index. Would be useful if your input sentence was list[Word]\n",
    "    print(\"Word index : \", test_text.word_ids(batch_index=0))\n",
    "\n",
    "    # The token type list, i.e. which sentence it belongs to, but we will not input pair of sentences here. \n",
    "    print(\"sentence id/sequence id/token type id : \", test_text.sequence_ids(batch_index=0))\n",
    "    print(\" ------- ------- ------- \")\n",
    "\n",
    "    # Below shows how to do some converting\n",
    "    char_i = 22\n",
    "    print(\"The character at index \", char_i, \" of the sentence is \", sen[char_i])\n",
    "    print(\"Its token index is at \", test_text.char_to_token(0, char_i), \" ,showing \", test_text.tokens(batch_index=0)[test_text.char_to_token(0, char_i)])\n",
    "\n",
    "\n",
    "# Test with a sentence from json_df\n",
    "test(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the annotaion into label\n",
    "\n",
    "### Before processing\n",
    "\n",
    "The raw data & annotation is like below:\n",
    "\n",
    "- Original sentence:  \n",
    "    ```\n",
    "    レッドフォックス株式会社は、東京都千代田区に本社を置くITサービス企業である。\n",
    "    ```\n",
    "\n",
    "- Original sentence size:  \n",
    "    ```\n",
    "    39\n",
    "    ```\n",
    "\n",
    "- Original label (json_df[\"entities\"][0]): \n",
    "    ```python\n",
    "    [\n",
    "        {'name': 'レッドフォックス株式会社', 'span': [0, 12], 'type': '法人名'},\n",
    "        {'name': '東京都千代田区', 'span': [14, 21], 'type': '地名'}\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "We would like to convert it into a form that easier to process later.\n",
    "\n",
    "- Desired label structure (for 1 sentence):  \n",
    "    (list with the same size as the original sentence )\n",
    "    ```python\n",
    "    ['B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'O', 'B-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "    ```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'レッドフォックス株式会社', 'span': [0, 12], 'type': '法人名'},\n",
       " {'name': '東京都千代田区', 'span': [14, 21], 'type': '地名'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the sample of record\n",
    "json_df[\"entities\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER tag set :  {'I-製品名', 'I-法人名', 'B-政治的組織名', 'O', 'I-人名', 'B-法人名', 'B-その他の組織名', 'B-製品名', 'B-施設名', 'I-施設名', 'I-地名', 'B-イベント名', 'I-政治的組織名', 'B-地名', 'B-人名', 'I-その他の組織名', 'I-イベント名'}\n",
      "a row of structured list : \n",
      "{'label': ['B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名',\n",
      "           'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'O', 'B-地名',\n",
      "           'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'I-地名', 'O', 'O',\n",
      "           'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "           'O'],\n",
      " 'text': 'レッドフォックス株式会社は、東京都千代田区に本社を置くITサービス企業である。'}\n",
      "The length of this label :  39\n",
      "The length of this sentence :  39\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "## 1. Convert the raw annotation into desired label structure for model training\n",
    "##    i.e. Restructure json_df[\"entities\"] into the same shape of sentence\n",
    "## 2. Build the NER tag mapping\n",
    "\n",
    "\n",
    "# We will use IOB tagging scheme\n",
    "# It will temporarily store the unique value of all labels\n",
    "ner_tag_set = set()\n",
    "# Add O <-- others\n",
    "ner_tag_set.add(\"O\")\n",
    "# We only need list structure from now on. Pandas is not good at looping row.\n",
    "json_list = json_df.to_dict('records')\n",
    "\n",
    "for index, row in enumerate(json_list):\n",
    "    # For each sentence at [index]\n",
    "    # e.g. row: { text: xxxx, entities: [...]}\n",
    "\n",
    "    # Form the label list as same size as the length of sentence, filled with O\n",
    "    label_list = [\"O\"] * len(row[\"text\"])\n",
    "    for entity in row[\"entities\"]:\n",
    "        # For each annotation data for this sentence\n",
    "        # e.g {'name': 'SPRiNGS', 'span': [0, 7], 'type': 'その他の組織名'}\n",
    "\n",
    "        ## Add 2 variants to dictionary set for future use\n",
    "        ner_tag_set.add(\"B-\" + entity[\"type\"])\n",
    "        ner_tag_set.add(\"I-\" + entity[\"type\"])\n",
    "\n",
    "        # the label location index at sentence\n",
    "        start = entity[\"span\"][0]\n",
    "        end = entity[\"span\"][1]\n",
    "\n",
    "        # set the label in label_list\n",
    "        label_list[start] = \"B-\" + entity[\"type\"]\n",
    "        label_list[start+1:end+1] = [\"I-\" + entity[\"type\"]] * (end - start) # the remained 1 is assigned in next line\n",
    "\n",
    "    # put it in the json_list\n",
    "    row[\"label\"] = label_list\n",
    "    # we don't need this anymore\n",
    "    del row[\"entities\"]\n",
    "\n",
    "\n",
    "print(\"NER tag set : \", ner_tag_set)\n",
    "print(\"a row of structured list : \")\n",
    "pp(json_list[1], compact=True)\n",
    "print(\"The length of this label : \", len(json_list[1][\"label\"]))\n",
    "print(\"The length of this sentence : \", len(json_list[1][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_tag_map with size:  17\n",
      "{'B-その他の組織名': 0, 'B-イベント名': 1, 'B-人名': 2, 'B-地名': 3, 'B-政治的組織名': 4, 'B-施設名': 5, 'B-法人名': 6, 'B-製品名': 7, 'I-その他の組織名': 8, 'I-イベント名': 9, 'I-人名': 10, 'I-地名': 11, 'I-政治的組織名': 12, 'I-施設名': 13, 'I-法人名': 14, 'I-製品名': 15, 'O': 16}\n",
      "{0: 'B-その他の組織名', 1: 'B-イベント名', 2: 'B-人名', 3: 'B-地名', 4: 'B-政治的組織名', 5: 'B-施設名', 6: 'B-法人名', 7: 'B-製品名', 8: 'I-その他の組織名', 9: 'I-イベント名', 10: 'I-人名', 11: 'I-地名', 12: 'I-政治的組織名', 13: 'I-施設名', 14: 'I-法人名', 15: 'I-製品名', 16: 'O'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## prepare the id to list, list to id mapper\n",
    "## They will be used in configuration of trainer\n",
    "## For the official doc, ref to https://huggingface.co/docs/transformers/main_classes/configuration#transformers.PretrainedConfig\n",
    "ner_tag_map = list(ner_tag_set)\n",
    "ner_tag_map.sort()\n",
    "print(\"ner_tag_map with size: \", len(ner_tag_map))\n",
    "\n",
    "label2id = { label: i for i, label in enumerate(ner_tag_map)}\n",
    "print(label2id)\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "print(id2label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データを `train`, `valid`, `test` に分割します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(json_list, test_size=0.2, random_state=123)\n",
    "train_data, test_data = train_test_split(train_data, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "[{'label': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "            'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "            'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      "            'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-人名', 'I-人名', 'I-人名',\n",
      "            'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'O', 'O', 'O'],\n",
      "  'text': '公式サイトは、2004年11月1日にリニューアルされており、デザインを担当したのはデザイナーのタケウエトモコである。'}]\n"
     ]
    }
   ],
   "source": [
    "## Lets check the train data\n",
    "print(type(train_data[0]))\n",
    "pp(train_data[:1], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの準備\n",
    "ベースモデルを用意します  \n",
    "ここで先ほどの `label2id`, `id2label` を渡してあげることで、推論時のラベル復元が楽になります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(model_name, label2id=label2id, id2label=id2label)\n",
    "model = BertForTokenClassification.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainerの準備\n",
    "TrainingArgumentsを設定し、Trainerを作成していきます  \n",
    "Trainerにはdata_collatorを渡してあげる必要があるので、data_collatorも作成します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_collatorは[transformersにすでにあるもの](https://huggingface.co/docs/transformers/main_classes/data_collator)を利用することもできますが、ここでは自前で定義していきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# This data_collator will be used by the trainer\n",
    "# and as a preprocess method when we do evaulation later.\n",
    "def data_collator(features: list) -> dict:\n",
    "    \"\"\"\n",
    "    The purpose of this method, is to tokenize the train data,\n",
    "    so we get all the required input(e.g. numeric tokens, attendence mask, ...etc)\n",
    "    Also we re-align the labels of sentences into labels of tokens,\n",
    "    according to the tokenized list. \n",
    "    \"\"\"\n",
    "    # Lets just use 64 as max length for simplicity\n",
    "    max_len = 64\n",
    "    tokenized_list = []\n",
    "    ## tokenized all text, while aligning the label list to match the result text\n",
    "    for index, row in enumerate(features):\n",
    "        # For each row at [index], e.g. { \"label\": [xxx], \"text\": \"xxxx\" }\n",
    "\n",
    "        # The return_offsets_mapping is so important here\n",
    "        # so that we can use it to re-align the labels\n",
    "        # The return_length let us know the length of the tokenized sentence (including CLS, SEP)\n",
    "        fast_result = fast_tokenizer(row[\"text\"], return_tensors=None, padding='max_length', \n",
    "                                    truncation=True, max_length=max_len, return_offsets_mapping=True,\n",
    "                                    return_length=True)\n",
    "\n",
    "        ## Build the aligned label list with prefilled values\n",
    "        ## The length here is same as tokens length in one sentence\n",
    "        ## NOTE: it includes special token [CLS][SEP][PAD]\n",
    "        y_each_sentence = [ -100 ] * len(fast_result.offset_mapping)\n",
    "\n",
    "        ## 'offset_mapping': [(0, 0), (0, 3), (3, 5), (5, 8), (8, 9), ...]\n",
    "        for index, offset_tuple in enumerate(fast_result.offset_mapping):\n",
    "            ## It is [PAD] already, break loop to save time\n",
    "            if index >= fast_result.length[0] :\n",
    "                break\n",
    "            ## If it is special token [CLS], [SEP] or [PAD], leave it as -100\n",
    "            if offset_tuple == (0, 0) : \n",
    "                continue\n",
    "            # Using our structured label list, get the annotation(its id value)\n",
    "            ## reminder: ['B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', ... ]\n",
    "            target_label = row[\"label\"][offset_tuple[0]] # e.g. 'B-法人名'\n",
    "            target_label_id = label2id[target_label] # e.g. 2\n",
    "            y_each_sentence[index] = target_label_id\n",
    "        \n",
    "        fast_result[\"labels\"] = y_each_sentence\n",
    "        # Remove unnecessary field, otherwise model training will throw error\n",
    "        del fast_result[\"offset_mapping\"]\n",
    "        del fast_result[\"length\"]\n",
    "        tokenized_list.append(fast_result)\n",
    "\n",
    "    # transpose\n",
    "    df_all = pd.DataFrame(tokenized_list)\n",
    "    dict_filter = df_all.to_dict(orient=\"list\")\n",
    "    # Convert all input to tensor, and put to specific CPU/GPU\n",
    "    batch = {k: torch.tensor(v, dtype=torch.int64).to(device) for k, v in dict_filter.items()}\n",
    "    return batch\n",
    "\n",
    "    # print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
      " 'input_ids': tensor([[    2, 11619, 24501, 28589, 28452,   113,    28,  1883,     5,  1273,\n",
      "            21,   415, 12246, 25457, 28503,     8,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]),\n",
      " 'labels': tensor([[-100,    0,    8,    8,    8,   16,   16,   16,   16,   16,   16,   16,\n",
      "           16,   16,   16,   16, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100]]),\n",
      " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "## lets test it before using in training\n",
    "a = data_collator(json_list[:1])\n",
    "pp(a, compact=True, depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハイパーパラメータなどを定義しておきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"./ckpt\"\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "learning_rate = 3e-5\n",
    "save_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(output_dir=ckpt_dir,\n",
    "                         do_train=True,\n",
    "                         do_eval=True,\n",
    "                         do_predict=True,\n",
    "                         per_device_train_batch_size=batch_size,\n",
    "                         per_device_eval_batch_size=batch_size,\n",
    "                         learning_rate=learning_rate,\n",
    "                         num_train_epochs=epochs,\n",
    "                         evaluation_strategy=\"steps\",\n",
    "                         eval_steps=save_freq,\n",
    "                         save_strategy=\"steps\",\n",
    "                         save_steps=save_freq,\n",
    "                         load_best_model_at_end=True,\n",
    "                         dataloader_pin_memory=False, #Important if you use gpu\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  data_collator=data_collator,\n",
    "                  train_dataset=train_data,\n",
    "                  eval_dataset=val_data,\n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習を実行します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3846\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 723\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='723' max='723' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [723/723 03:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.229417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.236402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.224432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1069\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./ckpt/checkpoint-100\n",
      "Configuration saved in ./ckpt/checkpoint-100/config.json\n",
      "Model weights saved in ./ckpt/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1069\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./ckpt/checkpoint-200\n",
      "Configuration saved in ./ckpt/checkpoint-200/config.json\n",
      "Model weights saved in ./ckpt/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1069\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./ckpt/checkpoint-300\n",
      "Configuration saved in ./ckpt/checkpoint-300/config.json\n",
      "Model weights saved in ./ckpt/checkpoint-300/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1069\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./ckpt/checkpoint-400\n",
      "Configuration saved in ./ckpt/checkpoint-400/config.json\n",
      "Model weights saved in ./ckpt/checkpoint-400/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1069\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./ckpt/checkpoint-500\n",
      "Configuration saved in ./ckpt/checkpoint-500/config.json\n",
      "Model weights saved in ./ckpt/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1069\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./ckpt/checkpoint-600\n",
      "Configuration saved in ./ckpt/checkpoint-600/config.json\n",
      "Model weights saved in ./ckpt/checkpoint-600/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1069\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./ckpt/checkpoint-700\n",
      "Configuration saved in ./ckpt/checkpoint-700/config.json\n",
      "Model weights saved in ./ckpt/checkpoint-700/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./ckpt/checkpoint-700 (score: 0.2244320660829544).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=723, training_loss=0.2925444163722121, metrics={'train_runtime': 180.758, 'train_samples_per_second': 63.831, 'train_steps_per_second': 4.0, 'total_flos': 376906354281216.0, 'train_loss': 0.2925444163722121, 'epoch': 3.0})"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できあがったモデルをテストします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 428\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.25463199615478516, 'test_runtime': 1.5567, 'test_samples_per_second': 274.945, 'test_steps_per_second': 17.345}\n"
     ]
    }
   ],
   "source": [
    "_, _, metrics = trainer.predict(test_data, metric_key_prefix=\"test\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルをsaveします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./dest\n",
      "Configuration saved in ./dest/config.json\n",
      "Model weights saved in ./dest/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの検証\n",
    "[seqeval](https://github.com/chakki-works/seqeval)を使って実際のモデル精度を検証していきます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論用の関数を定義\n",
    "学習したモデルを使って推論をするための関数を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'entities', 'label'])\n",
      "{'text': '若き科学者ハンク・マッコイはブランドコーポレーションで働き、ミューテーションの誘発物質を分離させる事ができた。', 'entities': [{'name': 'ハンク・マッコイ', 'span': [5, 13], 'type': '人名'}, {'name': 'ブランドコーポレーション', 'span': [14, 26], 'type': '法人名'}], 'label': ['O', 'O', 'O', 'O', 'O', 'B-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0].keys())\n",
    "print(test_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "## the function convert the train dataset into tokenized input for model, also align the label for comparing later\n",
    "\n",
    "def preprocess(each_dict: dict) -> dict:\n",
    "    # lets reuse the data_collator from above to do tokenization & label structuring\n",
    "    batch_dict = data_collator([each_dict])\n",
    "    return  batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'),\n",
      " 'input_ids': tensor([[    2,  1099,   322,   536,   112,   104,  2777, 28488,    35, 27492,\n",
      "         20418, 28450,  4536, 28476,  1551, 28774,  2260, 28456,  2131,   322,\n",
      "             6,  8826,  6977, 28444,  2325,    85,   410,  2015,    11,   155,\n",
      "          1022,  9293,   146,    29, 28456, 28512, 28447,     8,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]], device='cuda:0'),\n",
      " 'labels': tensor([[-100,   16,   16,   16,   16,   16,    2,   10,   10,   10,   10,   10,\n",
      "            6,   14,   14,   14,   14,   14,   16,   16,   16,   16,   16,   16,\n",
      "           16,   16,   16,   16,   16,   16,   16,   16,   16,   16,   16,   16,\n",
      "           16,   16, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100]], device='cuda:0'),\n",
      " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}\n",
      "tokenized sentence size (including CLS,SEP) :  39\n"
     ]
    }
   ],
   "source": [
    "## Lets try first\n",
    "tmp_test_after_preprocess = preprocess(test_data[0])\n",
    "pp.pprint(tmp_test_after_preprocess)\n",
    "print(\"tokenized sentence size (including CLS,SEP) : \", np.sum(tmp_test_after_preprocess[\"attention_mask\"][0].cpu().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./dest/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\",\n",
      "    \"1\": \"B-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\",\n",
      "    \"2\": \"B-\\u4eba\\u540d\",\n",
      "    \"3\": \"B-\\u5730\\u540d\",\n",
      "    \"4\": \"B-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\",\n",
      "    \"5\": \"B-\\u65bd\\u8a2d\\u540d\",\n",
      "    \"6\": \"B-\\u6cd5\\u4eba\\u540d\",\n",
      "    \"7\": \"B-\\u88fd\\u54c1\\u540d\",\n",
      "    \"8\": \"I-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\",\n",
      "    \"9\": \"I-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\",\n",
      "    \"10\": \"I-\\u4eba\\u540d\",\n",
      "    \"11\": \"I-\\u5730\\u540d\",\n",
      "    \"12\": \"I-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\",\n",
      "    \"13\": \"I-\\u65bd\\u8a2d\\u540d\",\n",
      "    \"14\": \"I-\\u6cd5\\u4eba\\u540d\",\n",
      "    \"15\": \"I-\\u88fd\\u54c1\\u540d\",\n",
      "    \"16\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\": 0,\n",
      "    \"B-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\": 1,\n",
      "    \"B-\\u4eba\\u540d\": 2,\n",
      "    \"B-\\u5730\\u540d\": 3,\n",
      "    \"B-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\": 4,\n",
      "    \"B-\\u65bd\\u8a2d\\u540d\": 5,\n",
      "    \"B-\\u6cd5\\u4eba\\u540d\": 6,\n",
      "    \"B-\\u88fd\\u54c1\\u540d\": 7,\n",
      "    \"I-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\": 8,\n",
      "    \"I-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\": 9,\n",
      "    \"I-\\u4eba\\u540d\": 10,\n",
      "    \"I-\\u5730\\u540d\": 11,\n",
      "    \"I-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\": 12,\n",
      "    \"I-\\u65bd\\u8a2d\\u540d\": 13,\n",
      "    \"I-\\u6cd5\\u4eba\\u540d\": 14,\n",
      "    \"I-\\u88fd\\u54c1\\u540d\": 15,\n",
      "    \"O\": 16\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ./dest/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./dest.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import BertForTokenClassification\n",
    "\n",
    "inference_model = BertForTokenClassification.from_pretrained(model_output_dir)\n",
    "inference_model.to(device)\n",
    "def inference(each_line_dict: dict) -> list:\n",
    "\n",
    "    input_dict = preprocess(each_line_dict)\n",
    "    # dict_keys(['attention_mask', 'input_ids', 'token_type_ids', 'labels'])\n",
    "    del input_dict['labels']\n",
    "    # Get tokenized sentence size\n",
    "    tokenized_length = np.sum(input_dict[\"attention_mask\"][0].cpu().tolist())\n",
    "\n",
    "    # Inference !\n",
    "    pred = inference_model(**input_dict).logits[0]\n",
    "    # print(np.shape(pred)) # torch.Size([64, 17])\n",
    "    pred = np.argmax(pred.cpu().detach().numpy(), axis=-1)\n",
    "    labels = []\n",
    "    for i, label in enumerate(pred):\n",
    "        # The last meaningful element is also a special token [SEP], so we ignore it\n",
    "        if i >= (tokenized_length-1): break\n",
    "        labels.append(inference_model.config.id2label[label])\n",
    "        # labels[i] = label\n",
    "    # Remove 1st element, which is [CLS]\n",
    "    labels.pop(0)\n",
    "    return pred[1:(tokenized_length-1)], labels\n",
    "    # return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction value: \n",
      "array([16, 16,  6, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "       16, 16, 16,  6, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "       16, 16])\n",
      "36\n",
      "--------\n",
      "Converted to label: \n",
      "['O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Lets test it\n",
    "temp_test_pred, temp_test_labels = inference(test_data[2])\n",
    "print(\"Prediction value: \")\n",
    "pp.pprint(temp_test_pred, compact=True)\n",
    "print(len(temp_test_pred))\n",
    "print(\"--------\")\n",
    "print(\"Converted to label: \")\n",
    "pp.pprint(temp_test_labels, compact=True)\n",
    "print(len(temp_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解データを用意します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "36\n",
      "(428,)\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "y_true = []\n",
    "for unit in test_data :\n",
    "    batch_dict = preprocess(unit)\n",
    "    tokenized_length = np.sum(batch_dict[\"attention_mask\"][0].cpu().tolist())\n",
    "    ylist = batch_dict[\"labels\"].tolist() \n",
    "\n",
    "    ylist = [ inference_model.config.id2label[eachVal if eachVal >= 0 else 16] for eachVal in ylist[0] ]\n",
    "    y_true.append(ylist[1:(tokenized_length-1)])\n",
    "\n",
    "pp.pprint(y_true[2], compact=True)\n",
    "print(len(y_true[2]))\n",
    "print(np.shape(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に推論結果も用意します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 'O', 'O', 'O', 'O', 'B-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'B-法人名', 'I-法人名', 'I-法人名', 'I-法人名', 'I-法人名',\n",
      "  'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
      " ['B-人名', 'I-人名', 'I-人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-地名', 'I-地名', 'I-地名', 'O', 'O', 'O',\n",
      "  'O', 'B-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'I-人名', 'O', 'O', 'O', 'O', 'O', 'O', 'B-地名', 'I-地名', 'I-地名', 'O', 'O',\n",
      "  'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for unit in test_data:\n",
    "    temp_test_pred, temp_test_label = inference(unit)\n",
    "    y_pred.append(temp_test_label)\n",
    "pp.pprint(y_pred[:2], compact=True, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-法人名', 'I-法人名', 'I-法人名', 'O', 'O', 'O',\n",
      " 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "'ただ日本自動車連盟は、1987年までF2車両による選手権を継続し、1988年からF3000に移行する考えであった。'\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(y_pred[2], compact=True)\n",
    "pp.pprint(train_data[2][\"text\"])\n",
    "print(len(train_data[2][\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seqevalのclassification_reportを実行\n",
    "seqevalのclassification_reportを使って検証します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     その他の組織名       0.52      0.74      0.61        68\n",
      "       イベント名       0.73      0.79      0.76        73\n",
      "          人名       0.87      0.89      0.88       248\n",
      "          地名       0.74      0.78      0.76       172\n",
      "      政治的組織名       0.66      0.76      0.71        85\n",
      "         施設名       0.60      0.74      0.66        72\n",
      "         法人名       0.65      0.79      0.71       214\n",
      "         製品名       0.59      0.65      0.62       102\n",
      "\n",
      "   micro avg       0.70      0.79      0.74      1034\n",
      "   macro avg       0.67      0.77      0.71      1034\n",
      "weighted avg       0.71      0.79      0.74      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "from seqeval.scheme import BILOU\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "#print(classification_report(y_true, y_pred, mode='strict', scheme=BILOU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seqevalのstrictモードは厳密なので精度は低くなりがちです  \n",
    "BILUOではstrictモードしかサポートされていないため、適宜BILUOをBIOに変換して使用するなど、タスクに合った精度検証を行ってください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論\n",
    "最後に、通常の推論用コードを紹介します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "def inference(text: str):\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_output_dir)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=64)\n",
    "    tokenized_length = np.sum(inputs[\"attention_mask\"][0].cpu().tolist())\n",
    "    pred = model(**inputs).logits[0]\n",
    "    pred = np.argmax(pred.detach().numpy(), axis=-1)\n",
    "    labels = []\n",
    "    for i, label in enumerate(pred):\n",
    "        if i > (tokenized_length-1): break\n",
    "        labels.append(inference_model.config.id2label[label])\n",
    "    labels.pop(0)\n",
    "    print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].cpu().tolist()))\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./dest/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./dest\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"B-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\",\n",
      "    \"1\": \"B-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\",\n",
      "    \"2\": \"B-\\u4eba\\u540d\",\n",
      "    \"3\": \"B-\\u5730\\u540d\",\n",
      "    \"4\": \"B-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\",\n",
      "    \"5\": \"B-\\u65bd\\u8a2d\\u540d\",\n",
      "    \"6\": \"B-\\u6cd5\\u4eba\\u540d\",\n",
      "    \"7\": \"B-\\u88fd\\u54c1\\u540d\",\n",
      "    \"8\": \"I-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\",\n",
      "    \"9\": \"I-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\",\n",
      "    \"10\": \"I-\\u4eba\\u540d\",\n",
      "    \"11\": \"I-\\u5730\\u540d\",\n",
      "    \"12\": \"I-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\",\n",
      "    \"13\": \"I-\\u65bd\\u8a2d\\u540d\",\n",
      "    \"14\": \"I-\\u6cd5\\u4eba\\u540d\",\n",
      "    \"15\": \"I-\\u88fd\\u54c1\\u540d\",\n",
      "    \"16\": \"O\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\": 0,\n",
      "    \"B-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\": 1,\n",
      "    \"B-\\u4eba\\u540d\": 2,\n",
      "    \"B-\\u5730\\u540d\": 3,\n",
      "    \"B-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\": 4,\n",
      "    \"B-\\u65bd\\u8a2d\\u540d\": 5,\n",
      "    \"B-\\u6cd5\\u4eba\\u540d\": 6,\n",
      "    \"B-\\u88fd\\u54c1\\u540d\": 7,\n",
      "    \"I-\\u305d\\u306e\\u4ed6\\u306e\\u7d44\\u7e54\\u540d\": 8,\n",
      "    \"I-\\u30a4\\u30d9\\u30f3\\u30c8\\u540d\": 9,\n",
      "    \"I-\\u4eba\\u540d\": 10,\n",
      "    \"I-\\u5730\\u540d\": 11,\n",
      "    \"I-\\u653f\\u6cbb\\u7684\\u7d44\\u7e54\\u540d\": 12,\n",
      "    \"I-\\u65bd\\u8a2d\\u540d\": 13,\n",
      "    \"I-\\u6cd5\\u4eba\\u540d\": 14,\n",
      "    \"I-\\u88fd\\u54c1\\u540d\": 15,\n",
      "    \"O\": 16\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ./dest/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ./dest.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/vocab.txt from cache at /home/jupyter/.cache/huggingface/transformers/15164357d71cd32532e56c1d7c2757141326ae17c53e2277bc417cc7c21da6ea.a7378a0cbee5cff668832a776d72b97a25479604fe9564d5595897f75049e7f4\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/tokenizer_config.json from cache at /home/jupyter/.cache/huggingface/transformers/0e46f722799f19c3f0c53172545108a4b31847d3b9a2d5b100759f6673bd667b.08ae4e4044742b9cc7172698caf1da2524f5597ff8cf848114dd0b730cc44bdc\n",
      "loading file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/tokenizer.json from cache at None\n",
      "loading configuration file https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/resolve/main/config.json from cache at /home/jupyter/.cache/huggingface/transformers/573af37b6c39d672f2df687c06ad7d556476cbe43e5bf7771097187c45a3e7bf.abeb707b5d79387dd462e8bfb724637d856e98434b6931c769b8716c6f287258\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '田中', 'さん', 'の', '会社', 'の', '社長', 'は', '鈴木', 'さん', 'です', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "['B-人名', 'I-人名', 'O', 'O', 'O', 'O', 'O', 'B-人名', 'I-人名', 'O', 'O']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(inference(\"田中さんの会社の社長は鈴木さんです\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "interpreter": {
   "hash": "8bd2744bd773c230c8aab7c92922cd19536a18d2951b06d8453826daa1b6f573"
  },
  "kernelspec": {
   "display_name": "Python [conda env:bertbersamplekento]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
